# coding=utf-8

# 监督学习

# 非监督学习

# 半监督学习

# 强化学习 经验中提取
    通过价值选行为
    直接选行为


    不理解环境(Model-Free RL)
        Q learning
        Sarsa
        Policy Gradients

    理解环境，并从中学习
        Model based RL
        想象力

    基于概率(Value Based RL)
        Policy Gradients

    基于价值(Policy Based RL)
        Q Learning
        Sarsa

    结合
        Actor-Critic

    回合更新(Monte-Carlo update)
        基础版Policy Gradients
        Monte-Carlo Learning

    单步更新(Temporal-Difference update)
        Q Learning
        Sarsa
        升级版Policy Gradients

    在线学习(On-Policy)
        Sarsa
        Sarsa(lambda)

    离线学习(Off-Policy)
        Q learning
        Deep Q network


# 遗传算法 适者生存

# GAN

# CNN
    卷积神经网络
    批量过滤器进行信息收集

# RNN
    有顺序要求
    前面的分析结果 参与 当前的决策
    循环神经网络

    梯度消失
    梯度爆炸

    LSMT
        长短期记忆
        主线剧情

        分线剧情

# 神经网络技巧
    1.检验神经网络
    训练集和测试集=7:3
    accuracy:
        R2
        F1

    Error:
        过拟合
        L1/L2 regulation
        Dropout

    交叉验证

    2.特征数据标准化
        minmax normalization (0,1)
        std normalization (mean=0,std=1)

    3.区分好特征
        避免无意义信息
        避免重复性信息
        避免复杂信息

    4.激励函数
        y=Wx
        解决不能用线性方程解决的问题
        y=AF(Wx)
        relu
        sigmoid
        tanh

        少量层：随便选
        cnn: relu
        rnn: relu 和 tanh

    5.过拟合
        自负
        训练集表现过好，测试集表现差强人意

        增加数据量
        L1,L2...regularization
        y=Wx
        误差值
        L1:cost=(Wx-real y)^2+abs(W)
        L2:cost=(Wx-real y)^2+（W)^2
        L3, L4...

        Dropout regularization
        随机忽略神经元

    6.加速神经网络
        SGD 批量化训练

        W+=-Learning rate*dx
        Momentum
        m=b1*m-Learning rate*dx
        W+=m

        W+=-Learning rate*dx
        AdaGrad
        v+=dx^2
        W+=-Learning rate*dx/v**(1/2)


        W+=-Learning rate*dx
        RMSProp
        v=b1*v+(1-b1)*dx^2
        W+=-Learning rate*dx/v**(1/2)

        优先:
        W+=-Learning rate*dx
        Adam
        m=b1*m+(1-b1)*dx ---Momentum
        v=b2*v+(1-b2)*d2^2
        W+=-Learning rate*m/v**(1/2)

    7.处理不均衡数据
        a.获取更多数据

        b.换个评判方式
            Confusion Matrix
            Precision & Recall
            F1 Score (or F-score)

        c.重组数据

        d.修改算法

    8.批标准化
        对隐藏层中的数据进行normalization
        全连接层和激励函数之间